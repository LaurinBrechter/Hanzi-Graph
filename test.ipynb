{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "CHROME_DRIVER_PATH = \"/home/laurinbrechter/Documents/chromedriver\"\n",
    "API_KEY = \"f6b2c0d8ac8bf83973a8cea901768bbd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dynamic_html(URL):\n",
    "    driver = webdriver.Chrome(executable_path = CHROME_DRIVER_PATH)\n",
    "    driver.get(URL)\n",
    "    soup = BeautifulSoup(driver.page_source)\n",
    "    driver.close()\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_word_container(word_container):\n",
    "    \"\"\"\n",
    "    Parses a single word container.\n",
    "    \"\"\"\n",
    "    chracter_container = word_container.find(class_=\"col-md-3 word-container\")\n",
    "    characters = [i.text for i in chracter_container.find(\"a\").find_all(\"span\")]\n",
    "\n",
    "    meanings = []\n",
    "    for child in list(word_container.find(class_=\"col-md-7\").find(\"p\").children)[2:]:\n",
    "        if child.name == \"a\":\n",
    "            meanings.append(child.text)\n",
    "\n",
    "    # meanings = [i.text for i in word_container.find(class_=\"col-md-7\").find(\"p\").find_all(\"a\")[1:-1]]\n",
    "\n",
    "    word_info = word_container.find(class_=\"pull-right\").find_all(\"span\")\n",
    "\n",
    "    word_type = word_info[0].text\n",
    "\n",
    "    for info in word_info:\n",
    "        if \"HSK\" in info.text:\n",
    "            hsk_level = info.text\n",
    "            break\n",
    "    else:\n",
    "        hsk_level = np.nan\n",
    "    \n",
    "\n",
    "    word_frequency_stars = len(word_info[-2].find_all(\"i\"))\n",
    "\n",
    "    return characters, meanings, word_type, hsk_level, word_frequency_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_word(soup:str):\n",
    "\n",
    "    meaning = []\n",
    "\n",
    "    char_container = soup.find(id=\"charDef\")\n",
    "    \n",
    "    pinyin = char_container.find(class_=\"arch-pinyin-font\").text\n",
    "    \n",
    "    radical = char_container.find(\"span\", string='»\\xa0Radical:\\xa0\\xa0').nextSibling.text\n",
    "    \n",
    "    try:\n",
    "        hsk_level = char_container.find(\"a\", string=\"HSK\").parent.nextSibling.text\n",
    "    except:\n",
    "        hsk_level = np.nan\n",
    "    \n",
    "    usage = len(list(soup.find(\"span\", {\"style\": \"color:#CCCCCC;\"}).children))\n",
    "    \n",
    "\n",
    "    for child in list(char_container.children)[1:]:\n",
    "        if child.name == \"a\":\n",
    "            meaning.append(child.text.strip())\n",
    "        elif child == \", \":\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    word_table = soup.find(class_=\"table table-condensed\")\n",
    "\n",
    "\n",
    "    # indicates wrong html\n",
    "    if not word_table:\n",
    "        return \"error\"\n",
    "\n",
    "\n",
    "    words = word_table.find_all(\"tr\")[1:]\n",
    "\n",
    "    word_information = []\n",
    "\n",
    "    for word in words:\n",
    "        try:\n",
    "            # if not word.get(\"id\"):\n",
    "            word_information.append(parse_word_container(word))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    parsed_word_information = pd.DataFrame(word_information, columns=[\"characters\", \"meanings\", \"word_type\", \"hsk_level\", \"word_frequency_stars\"])\n",
    "        \n",
    "    return pinyin, radical, hsk_level, usage, meaning, parsed_word_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.read_csv(\"data/hanzi_table.csv\")\n",
    "l1_words = words.loc[words[\"level\"] == 1]\n",
    "t = list(l1_words[\"Hanzi\"][50:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape(character_list, backend=\"web\"):\n",
    "\n",
    "    parsed_characters = []\n",
    "    parsed_words = []\n",
    "    for char in tqdm(character_list[10:]):\n",
    "        print(char, f\"https://www.archchinese.com/chinese_english_dictionary.html?find={char}\")\n",
    "        \n",
    "        if backend==\"web\":\n",
    "            soup = get_dynamic_html(f\"https://www.archchinese.com/chinese_english_dictionary.html?find={char}\")\n",
    "            with open(f\"html_data/html_{char}.html\", \"w\") as file:\n",
    "                file.write(str(soup))\n",
    "        elif backend==\"local\":\n",
    "            with open(f\"html_data/html_{char}.html\") as f:\n",
    "                x = f.read()\n",
    "            soup = BeautifulSoup(x)\n",
    "        else:\n",
    "            return\n",
    "\n",
    "        result = parse_word(soup)\n",
    "\n",
    "        if result == \"error\":\n",
    "            print(\"error with given html, retrying\")\n",
    "            while result == \"errror\":\n",
    "                result = parse_word(soup)\n",
    "\n",
    "\n",
    "        parsed_words.append(result[-1])\n",
    "        parsed_characters.append(result[:-1] + (char,))\n",
    "        \n",
    "        pd.DataFrame(pd.concat(parsed_words)).to_csv(\"words.csv\", index=False)\n",
    "        pd.DataFrame(parsed_characters, columns=[\"pinyin\", \"radical\", \"hsk_level\", \"usage\", \"meaning\", \"character\"]).to_csv(\"chars.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape(t, backend=\"web\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'丶': 'wán', '又': 'jí', '广': 'guǎng', '亠': 'wáng', '门': 'mén'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(parsed_characters)\n",
    "dict(zip(df[1], df[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'丶': 'wán', '又': 'jí', '广': 'guǎng', '亠': 'wáng', '门': 'mén'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i[1]:i[0] for i in parsed_characters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(parsed_words).to_csv(\"test-parse.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_text(l, text):\n",
    "    for i in l:\n",
    "        if i.text == text:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_edges(word_components: list[str]):\n",
    "    edges = []\n",
    "    for idx in range(len(word_components)-1):\n",
    "        # {'data': {'source': str(i[0]), 'target': str(i[1])}} for i in graph.edges()]\n",
    "        edges.append({\n",
    "            \"data\": {\n",
    "                \"source\": word_components[idx], \n",
    "                \"target\": word_components[idx+1],\n",
    "                \"class\": f\"word_length_{len(word_components)}\"\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "\n",
    "for word in parsed[0]:\n",
    "    edges += generate_edges(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed.to_csv(\"test-parse.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "node_set = []\n",
    "\n",
    "for row in parsed[0]:\n",
    "    for symbol in row:\n",
    "            if symbol not in nodes:\n",
    "                nodes.append(symbol)\n",
    "                node_set.append({\"data\": {\"id\": str(symbol), \"label\": str(symbol)}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test-parse.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['睾', '丸']</td>\n",
       "      <td>['testicle', '只']</td>\n",
       "      <td>[noun]</td>\n",
       "      <td>[M.W.: 只]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['肉', '丸']</td>\n",
       "      <td>['meatball', '只', '碗', '盘']</td>\n",
       "      <td>[noun]</td>\n",
       "      <td>[M.W.: 只碗盘]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['药', '丸']</td>\n",
       "      <td>['pill', '片', '粒', '颗']</td>\n",
       "      <td>[noun]</td>\n",
       "      <td>[M.W.: 片粒颗]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['丸', '子']</td>\n",
       "      <td>['pills', ' balls', ' meatballs', '只']</td>\n",
       "      <td>[noun]</td>\n",
       "      <td>[M.W.: 只]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['定', '心', '丸']</td>\n",
       "      <td>['tranquilizer', \"something that sets one's mi...</td>\n",
       "      <td>[noun]</td>\n",
       "      <td>[M.W.: 粒]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['弹', '丸']</td>\n",
       "      <td>['pellet', '粒', '块']</td>\n",
       "      <td>[noun]</td>\n",
       "      <td>[M.W.: 粒块]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['樟', '脑', '丸']</td>\n",
       "      <td>['camphor balls', ' moth balls', '粒', '颗']</td>\n",
       "      <td>[noun]</td>\n",
       "      <td>[M.W.: 粒颗]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['鱼', '丸']</td>\n",
       "      <td>['fish ball', '只']</td>\n",
       "      <td>[noun]</td>\n",
       "      <td>[M.W.: 只]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['炸', '丸', '子']</td>\n",
       "      <td>['croquettes', ' deep fried food balls', '只', ...</td>\n",
       "      <td>[noun]</td>\n",
       "      <td>[M.W.: 只碗盘]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>['牛', '肉', '丸']</td>\n",
       "      <td>['beef meatballs', '只', '碗', '盘', '碟', '份']</td>\n",
       "      <td>[noun]</td>\n",
       "      <td>[M.W.: 只碗盘碟份]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0                                                  1       2  \\\n",
       "0       ['睾', '丸']                                  ['testicle', '只']  [noun]   \n",
       "1       ['肉', '丸']                        ['meatball', '只', '碗', '盘']  [noun]   \n",
       "2       ['药', '丸']                            ['pill', '片', '粒', '颗']  [noun]   \n",
       "3       ['丸', '子']             ['pills', ' balls', ' meatballs', '只']  [noun]   \n",
       "4  ['定', '心', '丸']  ['tranquilizer', \"something that sets one's mi...  [noun]   \n",
       "5       ['弹', '丸']                               ['pellet', '粒', '块']  [noun]   \n",
       "6  ['樟', '脑', '丸']         ['camphor balls', ' moth balls', '粒', '颗']  [noun]   \n",
       "7       ['鱼', '丸']                                 ['fish ball', '只']  [noun]   \n",
       "8  ['炸', '丸', '子']  ['croquettes', ' deep fried food balls', '只', ...  [noun]   \n",
       "9  ['牛', '肉', '丸']        ['beef meatballs', '只', '碗', '盘', '碟', '份']  [noun]   \n",
       "\n",
       "                3  4  \n",
       "0       [M.W.: 只]  4  \n",
       "1     [M.W.: 只碗盘]  4  \n",
       "2     [M.W.: 片粒颗]  4  \n",
       "3       [M.W.: 只]  3  \n",
       "4       [M.W.: 粒]  2  \n",
       "5      [M.W.: 粒块]  2  \n",
       "6      [M.W.: 粒颗]  2  \n",
       "7       [M.W.: 只]  2  \n",
       "8     [M.W.: 只碗盘]  1  \n",
       "9   [M.W.: 只碗盘碟份]  1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_graph(df, \"丸\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97cc609b13305c559618ec78a438abc56230b9381f827f22d070313b9a1f3777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
